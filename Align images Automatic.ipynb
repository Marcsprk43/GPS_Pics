{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fbeb993",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "import json\n",
    "MAX_FEATURES = 500\n",
    "GOOD_MATCH_PERCENT = 0.15\n",
    "import pickle\n",
    "with open('/Users/sparky/Documents/DroneOpencv/coords.pickle', 'rb') as file:\n",
    "    gps_lst = pickle.load(file)\n",
    "pickup_cnt = 0\n",
    "dropoff_cnt = 0\n",
    "pickup_dict = {}\n",
    "dropoff_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf00e5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def click_event(event, x, y, flags, params):\n",
    "    global pickup_cnt, dropoff_cnt, pickup_dict, dropoff_dict\n",
    "    # checking for left mouse clicks\n",
    "    if event == cv2.EVENT_FLAG_CTRLKEY:\n",
    "        print(\"Pickups: {}\".format(pickup_dict))\n",
    "        print(\"Dropoffs: {}\".format(dropoff_dict))\n",
    "        return 1\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        print(\"Checking!\")\n",
    "        pickup_cnt += 1\n",
    "        # displaying the coordinates\n",
    "        # on the image window\n",
    "        cv2.circle(imReg, (x,y), 10, (255,255,255), 2)\n",
    "        cv2.circle(imReg, (x,y), 3, (0,0,255), 3)\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        cv2.putText(imReg, \"{:.8} {:.8}\".format(gps_lst[y][x][0],gps_lst[y][x][1]), (x,y), font,\n",
    "                    1, (0, 0, 255), 2)\n",
    "        print(\"Pickup #{}: {}, {}\".format(pickup_cnt, gps_lst[y][x][0], gps_lst[y][x][1]))\n",
    "        pickup_dict['pickup {}'.format(pickup_cnt)] = (gps_lst[y][x][0], gps_lst[y][x][1])\n",
    "        cv2.imshow('image', imReg)\n",
    "        cv2.waitKey(1)\n",
    "        print('ok')\n",
    "    elif event == cv2.EVENT_RBUTTONDOWN:\n",
    "        dropoff_cnt += 1\n",
    "        cv2.circle(imReg, (x,y), 10, (255,255,255), 2)\n",
    "        cv2.circle(imReg, (x,y), 3, (0,255,0), 3)\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        cv2.putText(imReg, \"{:.8} {:.8}\".format(gps_lst[y][x][0],gps_lst[y][x][1]), (x,y), font,\n",
    "                    1, (0, 255, 0), 2)\n",
    "        print(\"Dropoff #{}: {}, {}\".format(dropoff_cnt, gps_lst[y][x][0], gps_lst[y][x][1]))\n",
    "        dropoff_dict['dropoff {}'.format(dropoff_cnt)] = (gps_lst[y][x][0], gps_lst[y][x][1])\n",
    "        cv2.imshow('image', imReg)\n",
    "        cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b0e1180",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alignImages(im1, im2):\n",
    "    # Convert images to grayscale\n",
    "    im1Gray = cv2.cvtColor(im1, cv2.COLOR_BGR2GRAY)\n",
    "    im2Gray = cv2.cvtColor(im2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect ORB features and compute descriptors.\n",
    "    orb = cv2.ORB_create(MAX_FEATURES)\n",
    "    keypoints1, descriptors1 = orb.detectAndCompute(im1Gray, None)\n",
    "    keypoints2, descriptors2 = orb.detectAndCompute(im2Gray, None)\n",
    "\n",
    "    # Match features.\n",
    "    matcher = cv2.DescriptorMatcher_create(cv2.DESCRIPTOR_MATCHER_BRUTEFORCE_HAMMING)\n",
    "    matches = matcher.match(descriptors1, descriptors2, None)\n",
    "    matches = list(matches)\n",
    "\n",
    "    # Sort matches by score\n",
    "    matches.sort(key=lambda x: x.distance, reverse=False)\n",
    "\n",
    "    # Remove not so good matches\n",
    "    numGoodMatches = int(len(matches) * GOOD_MATCH_PERCENT)\n",
    "    matches = matches[:numGoodMatches]\n",
    "\n",
    "    # Draw top matches\n",
    "    imMatches = cv2.drawMatches(im1, keypoints1, im2, keypoints2, matches, None)\n",
    "    #cv2.imshow('matches', imMatches)\n",
    "    #cv2.waitKey(0)\n",
    "    #cv2.destroyAllWindows()\n",
    "    #cv2.imwrite(\"matches.jpg\", imMatches)\n",
    "\n",
    "    # Extract location of good matches\n",
    "    points1 = np.zeros((len(matches), 2), dtype=np.float32)\n",
    "    points2 = np.zeros((len(matches), 2), dtype=np.float32)\n",
    "\n",
    "    for i, match in enumerate(matches):\n",
    "        points1[i, :] = keypoints1[match.queryIdx].pt\n",
    "        points2[i, :] = keypoints2[match.trainIdx].pt\n",
    "    \n",
    "    # Find homography\n",
    "    h, mask = cv2.findHomography(points1, points2, cv2.RANSAC)\n",
    "\n",
    "    # Use homography\n",
    "    height, width, channels = im2.shape\n",
    "    im1Reg = cv2.warpPerspective(im1, h, (width, height))\n",
    "\n",
    "    return im1Reg, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4111058c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alignImages(sift, keypoints2, descriptors2, im1, im2):\n",
    "    # Convert images to grayscale\n",
    "    im1Gray = cv2.cvtColor(im1, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "\n",
    "    # Detect SIFT features and compute descriptors.\n",
    "    \n",
    "\n",
    "\n",
    "    keypoints1, descriptors1 = sift.detectAndCompute(im1Gray, None)\n",
    "    print(\"Test\")\n",
    "    # Match features.\n",
    "    FLAN_INDEX_KDTREE = 0\n",
    "    index_params = dict (algorithm = FLAN_INDEX_KDTREE, trees=5)\n",
    "    search_params = dict (checks=50)\n",
    "    flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "    good_matches = []\n",
    "    good_matches1 = []\n",
    "    matches = flann.knnMatch (descriptors1, descriptors2, k=2)\n",
    "    print(\"Test2\")\n",
    "    for m1, m2 in matches:\n",
    "      if m1.distance < 0.6 * m2.distance:\n",
    "        good_matches.append([m1])\n",
    "        good_matches1.append(m1)\n",
    "    # Sort matches by score\n",
    "    flann_matches =cv2.drawMatchesKnn(im1, keypoints1, im2, keypoints2, good_matches, None, flags=2)\n",
    "    cv2.imshow('image', flann_matches)\n",
    "    cv2.waitKey(0)\n",
    "    query_pts = np.float32([keypoints1[m.queryIdx] \n",
    "                .pt for m in good_matches1]).reshape(-1, 1, 2) \n",
    " \n",
    "    train_pts = np.float32([keypoints2[m.trainIdx] \n",
    "                    .pt for m in good_matches1]).reshape(-1, 1, 2) \n",
    "\n",
    "    h, mask = cv2.findHomography(query_pts, train_pts, cv2.RANSAC, 5.0) \n",
    "    height, width, channels = im2.shape\n",
    "    im1Reg = cv2.warpPerspective(im1, h, (width, height))\n",
    "    \n",
    "    \n",
    "    cv2.imshow(\"image\", im1Reg) \n",
    "    cv2.waitKey(0)\n",
    "    # Draw top matches\n",
    "    #imMatches = cv2.drawMatches(im1, keypoints1, im2, keypoints2, matches, None)\n",
    "    #cv2.imshow('matches', imMatches)\n",
    "    #cv2.waitKey(0)\n",
    "    #cv2.destroyAllWindows()\n",
    "    #cv2.imwrite(\"matches.jpg\", imMatches)\n",
    "\n",
    "    # Extract location of good matches\n",
    "    #points1 = np.zeros((len(matches), 2), dtype=np.float32)\n",
    "    #points2 = np.zeros((len(matches), 2), dtype=np.float32)\n",
    "\n",
    "    #for i, match in enumerate(matches):\n",
    "    #    points1[i, :] = keypoints1[match.queryIdx].pt\n",
    "    #    points2[i, :] = keypoints2[match.trainIdx].pt\n",
    "    \n",
    "    # Find homography\n",
    "    #h, mask = cv2.findHomography(points1, points2, cv2.RANSAC)\n",
    "\n",
    "    # Use homography\n",
    "    #height, width, channels = im2.shape\n",
    "    #im1Reg = cv2.warpPerspective(im1, h, (width, height))\n",
    "\n",
    "    return im1Reg, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434e9b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading reference image :  /Users/sparky/Documents/DroneOpencv/samplePics/image_0.jpeg\n",
      "Reading image to align :  /Users/sparky/Documents/DroneOpencv/samplePics/image_6.jpeg\n",
      "Aligning images ...\n",
      "Test\n",
      "Test2\n",
      "q!\n",
      "Reading image to align :  /Users/sparky/Documents/DroneOpencv/samplePics/image_7.jpeg\n",
      "Aligning images ...\n",
      "Test\n",
      "Test2\n",
      "q!\n",
      "Reading image to align :  /Users/sparky/Documents/DroneOpencv/samplePics/image_0.jpeg\n",
      "Aligning images ...\n",
      "Test\n",
      "Test2\n",
      "q!\n",
      "Reading image to align :  /Users/sparky/Documents/DroneOpencv/samplePics/image_1.jpeg\n",
      "Aligning images ...\n",
      "Test\n",
      "Test2\n",
      "q!\n",
      "Reading image to align :  /Users/sparky/Documents/DroneOpencv/samplePics/image_2.jpeg\n",
      "Aligning images ...\n",
      "Test\n",
      "Test2\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Read reference image\n",
    "    refFilename = \"/Users/sparky/Documents/DroneOpencv/samplePics/image_0.jpeg\"\n",
    "    print(\"Reading reference image : \", refFilename)\n",
    "    imBase = cv2.imread(refFilename, cv2.IMREAD_COLOR)\n",
    "    sift = cv2.SIFT_create(900)\n",
    "    im2Gray = cv2.cvtColor(imBase, cv2.COLOR_BGR2GRAY)\n",
    "    keypoints2, descriptors2 = sift.detectAndCompute(im2Gray, None)\n",
    "    for imFilename in listdir(\"/Users/sparky/Documents/DroneOpencv/samplePics/\"):\n",
    "        if imFilename.endswith('.jpeg'):\n",
    "            imFilename = \"/Users/sparky/Documents/DroneOpencv/samplePics/\" + imFilename\n",
    "            # Read image to be aligned\n",
    "            print(\"Reading image to align : \", imFilename)\n",
    "            imActual = cv2.imread(imFilename, cv2.IMREAD_COLOR)\n",
    "\n",
    "            print(\"Aligning images ...\")\n",
    "            # Registered image will be resotred in imReg.\n",
    "            # The estimated homography will be stored in h.\n",
    "            imReg, h = alignImages(sift, keypoints2, descriptors2, imActual, imBase)\n",
    "            added_image = cv2.addWeighted(imReg,0.5,imBase,0.5,0)\n",
    "            #print(\"Showing added image : \")\n",
    "            #cv2.imshow('added', added_image)\n",
    "            #cv2.waitKey(0)\n",
    "            #cv2.imwrite(outFilename, imReg)\n",
    "            cv2.imshow('image', added_image)\n",
    "            cv2.setMouseCallback('image', click_event)\n",
    "            while 1:\n",
    "                if cv2.waitKey(1) == ord('q'):\n",
    "                    print(\"q!\")\n",
    "                    break\n",
    "            # Print estimated homography\n",
    "    with open('/Users/sparky/Documents/DroneOpencv/POI_GPS.json', 'w') as file:\n",
    "                json.dump({'pickups':pickup_dict, 'dropoffs':dropoff_dict}, file)\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"Estimated homography : \\n\",  h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5538d5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/sparky/Documents/DroneOpencv/POI_GPS.json', 'r') as file:\n",
    "    coords = json.load(file)\n",
    "for coord in coords['pickups'].keys():\n",
    "    with open('/Users/sparky/Documents/DroneOpencv/{}.waypoints'.format(coord), 'w') as file:\n",
    "        file.writelines('QGC WPL 110 \\n')\n",
    "        file.writelines('0\\t1\\t0\\t16\\t0\\t0\\t0\\t0\\t33.520752\\t-84.581770\\t3144.245759\\t1\\n')\n",
    "        file.writelines('1\\t0\\t3\\t22\\t0.00000000\\t0.00000000\\t0.00000000\\t0.00000000\\t0.00000000\\t0.00000000\\t12.192000\\t1\\n')\n",
    "        file.writelines('2\\t0\\t3\\t16\\t0.00000000\\t0.00000000\\t0.00000000\\t0.00000000\\t{}\\t{}\\t12.192000\\t1\\n'.format(coords['pickups'][coord][0], coords['pickups'][coord][1]))\n",
    "        file.writelines('3\\t0\\t3\\t21\\t0.00000000\\t0.00000000\\t0.00000000\\t0.00000000\\t0.00000000\\t0.00000000\\t0.000000\\t1\\n')\n",
    "        file.writelines('4\\t0\\t3\\t211\\t0.00000000\\t1.00000000\\t0.00000000\\t0.00000000\\t0.00000000\\t0.00000000\\t0.000000')\n",
    "for coord in coords['dropoffs'].keys():\n",
    "    with open('/Users/sparky/Documents/DroneOpencv/{}.waypoints'.format(coord), 'w') as file:\n",
    "        file.writelines('QGC WPL 110 \\n')\n",
    "        file.writelines('0\\t1\\t0\\t16\\t0\\t0\\t0\\t0\\t33.520752\\t-84.581770\\t3144.245759\\t1\\n')\n",
    "        file.writelines('1\\t0\\t3\\t22\\t0.00000000\\t0.00000000\\t0.00000000\\t0.00000000\\t0.00000000\\t0.00000000\\t12.192000\\t1\\n')\n",
    "        file.writelines('2\\t0\\t3\\t16\\t0.00000000\\t0.00000000\\t0.00000000\\t0.00000000\\t{}\\t{}\\t12.192000\\t1\\n'.format(coords['dropoffs'][coord][0], coords['dropoffs'][coord][1]))\n",
    "        file.writelines('3\\t0\\t3\\t21\\t0.00000000\\t0.00000000\\t0.00000000\\t0.00000000\\t0.00000000\\t0.00000000\\t0.000000\\t1\\n')\n",
    "        file.writelines('4\\t0\\t3\\t211\\t0.00000000\\t0.00000000\\t0.00000000\\t0.00000000\\t0.00000000\\t0.00000000\\t0.000000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "535e1db8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.6.0'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e1e0794",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[thing for thing in dir(cv2) if \"xfeat\" in thing]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff181645",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
